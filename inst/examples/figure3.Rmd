  `ro cache=TRUE, warning=FALSE, comment=NA, message=FALSE, cache.path="figure3/", verbose=TRUE or`

``` {r  echo=FALSE, cache=FALSE }
#opts_knit$set(upload.fun = socialR::flickr.url)
#options(device = function(width = 5, height = 5) {
#    pdf(NULL, width = width, height = height)
#})
````

## Generate Figure 3 of Sethi et al. 2006

``` {r  setup, echo=FALSE, cache=FALSE}
# load required libraries
require(pdgControl)
require(reshape2)
require(ggplot2)
require(data.table)
rm(list=ls())
theme_publish <- theme_set(theme_bw(14))
theme_publish <- 
  theme_update(legend.key = theme_blank(),legend.position=c(.9,.1),
        panel.grid.major=theme_blank(),panel.grid.minor=theme_blank(),
        plot.background=theme_blank(), legend.title=theme_blank())

````

Chose the state equation / population dynamics function

``` {r }
f <- function(x,h,p){
  sapply(x, function(x){
  	S = max(x - h, 0)
  	p[1] * S * (1 - S/p[2]) + S
  })
}
````

With parameters `r` = `r r <- 1` and `K` = `r K <- 100`.

``` {r }
pars <- c(r, K)
````

We consider a profits from fishing to be a function of harvest `h` and stock size `x`,  \\( \Pi(x,h) = h - \left( c_0  + c_1 \frac{h}{x} \right) \frac{h}{x} \\), conditioned on \\( h > x \\) and \\(x > 0 \\),

``` {r  profit}
price <- 1
c0 <- 0.0
c1 <- 0
profit <- profit_harvest(price=price, c0 = c0, c1=c1) 
````

with price = `r price`, `c0` = `r c0` and `c1` = `r c1`. 


``` {r }
xmin <- 0
xmax <- 1.5 * K
grid_n <- 200
````

We seek a harvest policy which maximizes the discounted profit from the fishery using a stochastic dynamic programming approach over a discrete grid of stock sizes from `r xmin` to `r xmax` on a grid of `r grid_n` points, and over an identical discrete grid of possible harvest values.  


``` {r  grid}
x_grid <- seq(xmin, xmax, length = grid_n)  
h_grid <- x_grid  
````


``` {r miscpars}
delta <- 0.05
xT <- 0
OptTime <- 25
````

We will determine the optimal solution over a `r OptTime` time step window with boundary condition for stock at `r xT` and discounting rate of `r delta`.  

# Scenarios: 

--We use Monte Carlo integration over the noise processes to determine the transition matrix.--

We compute the transition probability analytically, (confirm that this is correct!)

$F(x,q) = \frac{1}{4\sigma_i\sigma_m} \int_{q-\sigma_i}^{q+\sigma_i} dh \int_{x-\sigma_m}^{x+\sigma_m} f(y, h)$


```{r }
require(cubature)
# Confirm that these give the same value, and time performance
system.time(a <- sapply(x_grid, function(x) int_f(f, x, 1, .1, .1, pars)))
system.time(b <- sapply(x_grid, function(x) F(x, 1, .1, .1, pars)))
```



``` {r beparallel, cache=FALSE, eval=FALSE}
require(snowfall)
sfInit(parallel=TRUE, cpu=16)
````

The policies

```{r}
stm <- SDP_uniform(f, pars, x_grid, h_grid, sigma_g=0.5, pdfn=function(P, s) dunif(P, 1-s, 1+s), sigma_m=0, sigma_i=0, F)
g <- find_dp_optim(stm, x_grid, h_grid, OptTime, xT, profit, delta, reward=0)
stm <- SDP_uniform(f, pars, x_grid, h_grid, sigma_g=0, pdfn=function(P, s) dunif(P, 1-s, 1+s), sigma_m=0.5, sigma_i=0, F)
m <- find_dp_optim(stm, x_grid, h_grid, OptTime, xT, profit, delta, reward=0)
stm <- SDP_uniform(f, pars, x_grid, h_grid, sigma_g=0, pdfn=function(P, s) dunif(P, 1-s, 1+s), sigma_m=0, sigma_i=0.5, F)
i <- find_dp_optim(stm, x_grid, h_grid, OptTime, xT, profit, delta, reward=0)
stm <- SDP_uniform(f, pars, x_grid, h_grid, sigma_g=0.1, pdfn=function(P, s) dunif(P, 1-s, 1+s), sigma_m=0.1, sigma_i=0.1, F)
low <- find_dp_optim(stm, x_grid, h_grid, OptTime, xT, profit, delta, reward=0)
```



``` {r policyscenarios, eval=FALSE, include=FALSE} 
# not run
scenario <- function(policy_g, policy_m, policy_i){ 
  z_g <- function() 1+(2*runif(1, 0,  1)-1) * policy_g
  z_m <- function() 1+(2*runif(1, 0,  1)-1) * policy_m
  z_i <- function() 1+(2*runif(1, 0,  1)-1) * policy_i
  SDP_Mat <- SDP_by_simulation(f, pars, x_grid, h_grid, z_g, z_m, z_i, reps=2e4)
  opt <- find_dp_optim(SDP_Mat, x_grid, h_grid, OptTime, xT, 
                       profit, delta, reward=0)
}
````


Do the deterministic exactly,

```{r deterministic}
pdfn <- function(P, s){
     dunif(P, 1 - s, 1 + s)
}
SDP_Mat <- determine_SDP_matrix(f, pars, x_grid, h_grid, sigma_g = 0.5, pdfn)
det <- find_dp_optim(SDP_Mat, x_grid, h_grid, OptTime, xT, profit, delta, reward=0)
````


``` {r runall, eval=FALSE, include=FALSE}
lvl <- 0.5
low <- scenario(0.1, 0.1, 0.1)
g   <- scenario(lvl, 0, 0)
m   <- scenario(0, lvl, 0)
i   <- scenario(0, 0, lvl)
````

### plots



``` {r sethiplots, cache=FALSE}
require(reshape2)
policy <- melt(data.frame(stock = x_grid, deterministic=det$D[,1], all_low = low$D[,1],
               growth = g$D[,1], measurement = m$D[,1], implementation = i$D[,1]), 
               id = "stock")

ggplot(policy) + geom_point(aes(stock, stock-x_grid[value], color=variable), shape="+")
dat <- subset(policy, stock < 140)
dt <- data.table(dat)
linear <- dt[,approx(stock, stock-x_grid[value], xout=seq(1,150, length=15)), by=variable]
ggplot(linear) + 
	stat_smooth(aes(x,y,color=variable), degree=1, se=FALSE, span=.3) + 
	xlab("Measured Stock") + ylab("Optimal Expected Escapement")
```

